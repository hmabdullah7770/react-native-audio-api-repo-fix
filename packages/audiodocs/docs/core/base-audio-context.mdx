---
sidebar_position: 1
---

import { Optional, ReadOnly, MobileOnly } from '@site/src/components/Badges';

# BaseAudioContext

The `BaseAudioContext` interface acts as a supervisor of audio-processing graphs. It provides key processing parameters such as current time, output destination or sample rate.
Additionally, it is responsible for nodes creation and audio-processing graph's lifecycle management.
However, `BaseAudioContext` itself cannot be directly utilized, instead its functionalities must be accessed through one of its derived interfaces: [`AudioContext`](/docs/core/audio-context), [`OfflineAudioContext`](/docs/core/offline-audio-context).

#### Audio graph

An audio graph is a structured representation of audio processing elements and their connections within an audio context.
The graph consists of various types of nodes, each performing specific audio operations, connected in a network that defines the audio signal flow.
In general we can distinguish four types of nodes:
- Source nodes (e.g [`AudioBufferSourceNode`](/docs/sources/audio-buffer-source-node), [`OscillatorNode`](/docs/sources/oscillator-node))
- Effect nodes (e.g [`GainNode`](/docs/effects/gain-node), [`BiquadFilterNode`](/docs/effects/biquad-filter-node))
- Analysis nodes (e.g [`AnalyserNode`](/docs/analysis/analyser-node))
- Destination nodes (e.g [`AudioDestinationNode`](/docs/destinations/audio-destination-node))

![](/img/audio-graph.png)

#### Rendering audio graph

Audio graph rendering is done in blocks of sample-frames. The number of sample-frames in a block is called render quantum size, and the block itself is called a render quantum.
By default render quantum size value is 128 and it is constant.

The [`AudioContext`](/docs/core/audio-context) rendering thread is driven by a system-level audio callback.
Each call has a system-level audio callback buffer size, which is a varying number of sample-frames that needs to be computed on time before the next system-level audio callback arrives,
but render quantum size does not have to be a divisor of the system-level audio callback buffer size.

:::info
Concept of system-level audio callback does not apply to [`OfflineAudioContext`](/docs/core/offline-audio-context).
:::

## Properties

| Name | Type | Description | |
| :----: | :----: | :-------- | :-: |
| `currentTime` | `number` | Double value representing an ever-increasing hardware time in seconds, starting from 0. | <ReadOnly /> |
| `destination` | [`AudioDestinationNode`](/docs/destinations/audio-destination-node) | Final output destination associated with the context. | <ReadOnly /> |
| `sampleRate` | `number` | Float value representing the sample rate (in samples per seconds) used by all nodes in this context. | <ReadOnly /> |
| `state` | [`ContextState`](/docs/core/base-audio-context#contextstate) | Enumerated value represents the current state of the context. | <ReadOnly /> |

## Methods

### `createAnalyser`

Creates [`AnalyserNode`](/docs/analysis/analyser-node).

#### Returns `AnalyserNode`.

### `createRecorderAdapter`

Creates [`RecorderAdapterNode`](/docs/sources/recorder-adapter-node).

#### Returns `RecorderAdapterNode`

### `createWorkletNode` <MobileOnly />

Creates [`WorkletNode`](/docs/worklets/worklet-node).

| Parameters | Type | Description |
| :---: | :---: | :---- |
| `worklet` | `(Array<Float32Array>, number) => void` | The worklet to be executed. |
| `bufferLength` | `number` | The size of the buffer that will be passed to the worklet on each call. |
| `inputChannelCount` | `number` | The number of channels that the node expects as input (it will get min(expected, provided)). |

#### Errors

| Error type | Description |
| :---: | :---- |
| `Error` | `react-native-worklet` is not found as dependency. |
| `NotSupportedError` | `bufferLength` < 1. |
| `NotSupportedError` | `inputChannelCount` is not in range [1, 32]. |

#### Returns `WorkletNode`.

### `createBuffer`

Creates [`AudioBuffer`](/docs/sources/audio-buffer).

| Parameters | Type | Description |
| :---: | :---: | :---- |
| `numOfChannels` | `number` | An integer representing the number of channels of the buffer. |
| `length` | `number` | An integer representing the length of the buffer in sampleFrames. Two seconds buffer has length equals to `2 * sampleRate`. |
| `sampleRate` | `number` | A float representing the sample rate of the buffer. |

#### Errors

| Error type | Description |
| :---: | :---- |
| `NotSupportedError` | `numOfChannels` is outside the nominal range [1, 32]. |
| `NotSupportedError` | `sampleRate` is outside the nominal range [8000, 96000]. |
| `NotSupportedError` | `length` is less then 1. |

#### Returns `AudioBuffer`.

### `createBufferSource`

Creates [`AudioBufferSourceNode`](/docs/sources/audio-buffer-source-node).

| Parameters | Type | Description |
| :---: | :---: | :---- |
| `pitchCorrection` <Optional /> | [`AudioBufferBaseSourceNodeOptions`](/docs/sources/audio-buffer-source-node#constructor) | Dictionary object that specifies if pitch correction has to be available. |

#### Returns `AudioBufferSourceNode`.

### `createBufferQueueSource` <MobileOnly />

Creates [`AudioBufferQueueSourceNode`](/docs/sources/audio-buffer-queue-source-node).

| Parameters | Type | Description |
| :---: | :---: | :---- |
| `pitchCorrection` <Optional /> | [`AudioBufferBaseSourceNodeOptions`](/docs/sources/audio-buffer-queue-source-node#constructor) | Dictionary object that specifies if pitch correction has to be available. |

#### Returns `AudioBufferQueueSourceNode`.

### `createGain`

Creates [`GainNode`](/docs/effects/gain-node).

#### Returns `GainNode`.

### `createOscillator`

Creates [`OscillatorNode`](/docs/sources/oscillator-node).

#### Returns `OscillatorNode`.

### `createStreamer` <MobileOnly />

Creates [`StreamerNode`](/docs/sources/streamer-node).

#### Returns `StreamerNode`.

### `createPeriodicWave`

Creates [`PeriodicWave`](/docs/effects/periodic-wave). This waveform specifies a repeating pattern that an OscillatorNode can use to generate its output sound.

| Parameters | Type | Description |
| :---: | :---: | :---- |
| `real` | `Float32Array` | An array of cosine terms. |
| `imag` | `Float32Array` | An array of sine terms. |
| `constraints` <Optional /> | [`PeriodicWaveConstraints`](/docs/core/base-audio-context#periodicwaveconstraints) | An object that specifies if normalization is disabled. If so, periodic wave will have maximum peak value of 1 and minimum peak value of -1.|

#### Errors

| Error type | Description |
| :---: | :---- |
| `InvalidAccessError` | `real` and `imag` arrays do not have same length. |

#### Returns `PeriodicWave`.

### `createStereoPanner`

Creates [`StereoPannerNode`](/docs/effects/stereo-panner-node).

#### Returns `StereoPannerNode`.

### `createBiquadFilter`

Creates [`BiquadFilterNode`](/docs/effects/biquad-filter-node).

#### Returns `BiquadFilterNode`.

:::caution
Supported file formats:
- mp3
- wav
- flac
- opus
- ogg
- m4a
- aac
- mp4
:::

### `decodeAudioData`

<details>
<summary>Example</summary>
```tsx
const url = ... // url to an audio

const buffer = await fetch(url)
  .then((response) => response.arrayBuffer())
  .then((arrayBuffer) => this.audioContext.decodeAudioData(arrayBuffer))
  .catch((error) => {
    console.error('Error decoding audio data source:', error);
    return null;
  });
```
</details>

Decodes audio data. It decodes with in memory audio data block.

| Parameters | Type | Description |
| :---: | :---: | :---- |
| `arrayBuffer` | `ArrayBuffer` | ArrayBuffer with audio data. |

#### Returns `Promise<AudioBuffer>`.

### `decodeAudioDataSource`

<details>
<summary>Example using expo-asset library</summary>
```tsx
import { Asset } from 'expo-asset';

const buffer = await Asset.fromModule(require('@/assets/music/example.mp3'))
    .downloadAsync()
    .then((asset) =>  {
      if (!asset.localUri) {
        throw new Error('Failed to load audio asset');
      }
      return this.audioContext.decodeAudioDataSource(asset.localUri);
    })
```
</details>

Decodes audio data file.

| Parameters | Type | Description |
| :---: | :---: | :---- |
| `sourcePath` | `string` | Path to audio file located on the device. |

#### Returns `Promise<AudioBuffer>`.

### `decodePCMInBase64Data` <MobileOnly />

<details>
<summary>Example</summary>
```tsx
const data = ... // data encoded in base64 string
const buffer = await this.audioContext.decodePCMInBase64Data(data);
```
</details>

Decodes audio data. It decodes with PCM data in Base64.

| Parameters | Type | Description |
| :---: | :---: | :---- |
| `base64` | `string` | Base64 string with audio data. |
| `playbackRate` <Optional /> | `number` | Number that represents audio speed, which will be applied during decoding. |

#### Returns `Promise<AudioBuffer>`.

## Remarks

#### `currentTime`

- Timer starts when context is created, stops when context is suspended.

### `ContextState`

<details>

**Acceptable values:**
  - `suspended`

  The audio context has been suspended (with one of [`suspend`](/docs/core/audio-context#suspend) or [`OfflineAudioContext.suspend`](/docs/core/offline-audio-context#suspend)).

  - `running`

  The audio context is running normally.

  - `closed`

  The audio context has been closed (with [`close`](/docs/core/audio-context#close) method).
</details>
